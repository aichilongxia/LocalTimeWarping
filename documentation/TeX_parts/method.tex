
Consider the mapping $F: t^{r}_{1:T} \mapsto t^{w}_{1:T}$ that maps the time indexes of a reference 
trajectory with associated time vector $t^{r}_{1:T}$ to a query trajectory whose associated time vector $t^{w}_{1:T}$ is to be found.
Note that one of the trajectories must be resampled such that both query and reference trajectories have the same number of time steps $T$.
The algorithm does not modify the number of time steps, but the duration between each time step.
Define the cumulative cost based on DTW as 
\begin{equation}
	C = \sum_{t=1}^T \| \bi x^r( t^{r}_t) - \bi x^q( t^w_t )    \|,
	\label{eq:dtwcost}
\end{equation}
where $\bi x^r$ is the reference trajectory for time alignment, and $\bi x^q$ is the query trajectory to be aligned.

The goal of the method is to find a warping mapping function $F$ such that the cumulative cost is minimized.
We initially parameterize the warping function with parameters $\bi \theta = \{\theta_0, \ \bi \theta_w\}$ such that
%\begin{equation}
%	\begin{split}
%		t^w_{1:T} & = \theta_0 + f(\bi \theta_w)  t^{r}_{1:T}\\
%	        	  & = \theta_0 + \Psi \theta_w  t^{r}_{1:T}
%	\end{split}	
%\end{equation}
\begin{equation}
	\bi s_{1:T}  = f(\bi \theta_w),
	\label{eq:ss}
\end{equation}
and 
\begin{equation}
	\bi t^w_{1:T}  = \theta_0 + \bi s \odot \bi t^{r}_{1:T}.
	\label{eq:ww}
\end{equation}
The function $f(\bi \theta_w)$ is the local warping function, previously illustrated in Fig.~\ref{fig:dtwss}(b) and returns a vector of scaling values for each time step of the original reference time.
In \eqref{eq:ww}, the  second term is the element wise product of $\bi s_{1:T}$ and the reference time  $\bi t^r_{1:T}$.

The scalar parameter $\theta_0$ changes the start instant of $t^w_{1:T}$.
This is useful when both reference and query trajectories are identically in shape, but start at different times.
%
%The second term is the product of a diagonal warping matrix $\bi W \in \mathbb{R}^{T \times T}$ and the reference time  $\bi t^r_{1:T} \in \mathbb{R}^T$.
%
In the particular case when the reference and query trajectories are already aligned, $\theta_0=0$ and \eqref{eq:ss} returns a vector of ones.
This is usually the standard initial guess of parameters to initialize the optimization.

To enforce that $f(\bi \theta_w)$ is a smooth function, we use the parameterization
\begin{equation}
	\bi s_t = \sum_{n=1}^N  \bi (\Phi_t)_n \bi (\theta_w)_n.
	\label{eq:st}
\end{equation}
where $(\Phi_t)_n$ is the value of the n-th radial basis function at time $t$. 
The dimension of $\bi \theta_w \in \mathbb{R}^{N}$ is the defined by the number of $N$ basis functions to be used.


The method consists in using a local optimization method, such as gradient descent, to update $\bi \theta = \{\theta_0, \ \bi \theta_w\}$ such that the cost 	\eqref{eq:dtwcost} is minimized.
In the current implementation, gradient descent with Jacobian computed by finite differences is used.
The source code with an example can be found in


%The pseudo-code is provided in 
%
%\begin{algorithm}
%	\caption{Local Time Warping}\label{ltw}
%	\begin{algorithmic}[1]
%		\For{ $k < nMax$ or Converged }
%		\State $\bi \theta_{k}  \gets \bi \theta_{k-1} + \alpha \bi J^{-1} C$
%		\State $\bi t^w_{1:T} \gets \text{NewTimeWarping}(  \theta_0, \  \bi s_{1:T}, \ \bi t^{r}_{1:T}) $
%		\State $C \gets \text{ComputeCumulativeCost}( \bi x^q( t^w_t ),\  \bi x^r( t^r_t )  ) $.		
%		%		\State $i \gets i+\max(\textit{delta}_1(\textit{string}(i)),\textit{delta}_2(j))$.
%		%		\EndProcedure
%		\EndFor
%	\end{algorithmic}
%\end{algorithm}
%
%\begin{algorithm}
%	\caption{Local Time Warping}\label{euclid}
%	\begin{algorithmic}[1]
%%		\State $\textit{stringlen} \gets \text{length of }\textit{string}$%
%%		\State $i \gets \textit{patlen}$
%%		\If {$i > \textit{stringlen}$} \Return false
%%		\EndIf
%%		\State $ \gets \textit{patlen}$
%%		\If {$\textit{string}(i) = \textit{path}(j)$}
%%		\State $j \gets j-1$.
%		\For{ $k < nMax$ or Converged }
%		\State $\bi s_{1:T}  \gets  f(\bi \theta_w)$ //compute scaling vector with \eqref{eq:st}
%		\State $\bi t^w_{1:T} \gets \text{NewTimeWarping}(  \theta_0, \  \bi s_{1:T}, \ \bi t^{r}_{1:T}) $
%		\State $C \gets \text{ComputeCumulativeCost}( \bi x^q( t^w_t ),\  \bi x^r( t^r_t )  ) $.		
%%		\State $i \gets i+\max(\textit{delta}_1(\textit{string}(i)),\textit{delta}_2(j))$.
%%		\EndProcedure
%		\EndFor
%	\end{algorithmic}
%\end{algorithm}


